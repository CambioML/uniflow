{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbc4c4a",
   "metadata": {},
   "source": [
    "# Example of generating QAs for an ML book (using self-instruct)\n",
    "Source: https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html\n",
    "\n",
    "### Before running the code\n",
    "\n",
    "You will need to have the following packages installed:\n",
    "```\n",
    "pip install langchain pandas unstructured\n",
    "```\n",
    "\n",
    "Also, make sure you have a .env file with your OpenAI API key in the root directory of this project.\n",
    "```\n",
    "OPENAI_API_KEY=YOUR_API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d84dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseortiz/anaconda3/envs/uniflow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.config import TransformOpenAIConfig\n",
    "from uniflow.op.model.model_config import OpenAIModelConfig\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from uniflow.op.prompt_schema import Context, GuidedPrompt\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb677037",
   "metadata": {},
   "source": [
    "## Prepare the input data\n",
    "\n",
    "Uncomment any of the html files below as the sample file to build the self-instruct flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a707ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#html_file = \"do_things_that_dont_scale.html\" #from http://paulgraham.com/ds.html\n",
    "#html_file = \"makers_schedule_managers_schedule.html\" #from http://www.paulgraham.com/makersschedule.html\n",
    "#html_file = \"life_is_short.html\" #http://www.paulgraham.com/vb.html\n",
    "html_file = \"22.11_information-theory.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b177df1",
   "metadata": {},
   "source": [
    "Set current directory and input data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092b355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_cur = os.getcwd()\n",
    "input_file = os.path.join(f\"{dir_cur}/data/raw_input/\", html_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(input_file)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_prompt = GuidedPrompt(\n",
    "        instruction=\"Generate one question and its corresponding answer based on context. Following the format of the examples below to include the same context, question, and answer in the response.\",\n",
    "        examples=[\n",
    "            Context(\n",
    "                context=\"In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.\",\n",
    "                question=\"Who published A Mathematical Theory of Communication in 1948?\",\n",
    "                answer=\"Claude E. Shannon.\",\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "data = [ Context(context=p) for p in pages[2].page_content.split(\"\\n\\n\") if len(p) > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(context='Any notion of information we develop must conform to this intuition.\\nIndeed, in the next sections we will learn how to compute that these\\nevents have \\\\(0\\\\textrm{ bits}\\\\), \\\\(2\\\\textrm{ bits}\\\\),\\n\\\\(~5.7\\\\textrm{ bits}\\\\), and \\\\(~225.6\\\\textrm{ bits}\\\\) of\\ninformation respectively.'),\n",
       " Context(context='If we read through these thought experiments, we see a natural idea. As\\na starting point, rather than caring about the knowledge, we may build\\noff the idea that information represents the degree of surprise or the\\nabstract possibility of the event. For example, if we want to describe\\nan unusual event, we need a lot information. For a common event, we may\\nnot need much information.'),\n",
       " Context(context='In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[-3:]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ModelFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformOpenAIConfig(\n",
    "    guided_prompt_template=guided_prompt,\n",
    "    model_config=OpenAIModelConfig(response_format={\"type\": \"json_object\"}),\n",
    ")\n",
    "client = TransformClient(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "output = client.run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': [{'response': [{'context': 'Any notion of information we develop must conform to this intuition. Indeed, in the next sections we will learn how to compute that these events have \\\\(0\\\\textrm{ bits}\\\\), \\\\(2\\\\textrm{ bits}\\\\), \\\\(~5.7\\\\textrm{ bits}\\\\), and \\\\(~225.6\\\\textrm{ bits}\\\\) of information respectively.',\n",
       "      'question': 'How many bits of information do these events have?',\n",
       "      'answer': '0 bits, 2 bits, ~5.7 bits, and ~225.6 bits.'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x28d4dcd60>},\n",
       " {'output': [{'response': [{'context': 'If we read through these thought experiments, we see a natural idea. As a starting point, rather than caring about the knowledge, we may build off the idea that information represents the degree of surprise or the abstract possibility of the event. For example, if we want to describe an unusual event, we need a lot information. For a common event, we may not need much information.',\n",
       "      'question': 'What does information represent according to the given context?',\n",
       "      'answer': 'The degree of surprise or the abstract possibility of the event.'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x1038a8940>},\n",
       " {'output': [{'response': [{'context': 'In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.',\n",
       "      'question': 'What concept did Claude E. Shannon introduce for the first time in his article?',\n",
       "      'answer': 'The concept of information entropy.'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x28d4dc9a0>}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format result into pandas table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any notion of information we develop must conform to this intuition. Indeed, in the next sections we will learn how to compute that these events have \\(0\\textrm{ bits}\\), \\(2\\textrm{ bits}\\), \\(~5.7\\textrm{ bits}\\), and \\(~225.6\\textrm{ bits}\\) of information respectively.</td>\n",
       "      <td>How many bits of information do these events have?</td>\n",
       "      <td>0 bits, 2 bits, ~5.7 bits, and ~225.6 bits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If we read through these thought experiments, we see a natural idea. As a starting point, rather than caring about the knowledge, we may build off the idea that information represents the degree of surprise or the abstract possibility of the event. For example, if we want to describe an unusual event, we need a lot information. For a common event, we may not need much information.</td>\n",
       "      <td>What does information represent according to the given context?</td>\n",
       "      <td>The degree of surprise or the abstract possibility of the event.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.</td>\n",
       "      <td>What concept did Claude E. Shannon introduce for the first time in his article?</td>\n",
       "      <td>The concept of information entropy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                           context                                                                         question                                                            answer\n",
       "0                                                                                                                Any notion of information we develop must conform to this intuition. Indeed, in the next sections we will learn how to compute that these events have \\(0\\textrm{ bits}\\), \\(2\\textrm{ bits}\\), \\(~5.7\\textrm{ bits}\\), and \\(~225.6\\textrm{ bits}\\) of information respectively.                               How many bits of information do these events have?                       0 bits, 2 bits, ~5.7 bits, and ~225.6 bits.\n",
       "1  If we read through these thought experiments, we see a natural idea. As a starting point, rather than caring about the knowledge, we may build off the idea that information represents the degree of surprise or the abstract possibility of the event. For example, if we want to describe an unusual event, we need a lot information. For a common event, we may not need much information.                  What does information represent according to the given context?  The degree of surprise or the abstract possibility of the event.\n",
       "2                                                                                                                                 In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.  What concept did Claude E. Shannon introduce for the first time in his article?                               The concept of information entropy."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting context, question, and answer into a DataFrame\n",
    "contexts = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for item in output:\n",
    "    for i in item['output']:\n",
    "        for response in i['response']:\n",
    "            contexts.append(response['context'])\n",
    "            questions.append(response['question'])\n",
    "            answers.append(response['answer'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'context': contexts,\n",
    "    'question': questions,\n",
    "    'answer': answers\n",
    "})\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', None)  # or use a specific width like 50\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-instruct-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
